{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of Negational Symmetry of QNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_quantum as tfq\n",
    "\n",
    "import models\n",
    "import utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "NUM_QUBITS = 16\n",
    "\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = utils.get_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 Validation of Negational Symmetry\n",
    "### Part 1.1 Binary Pattern Classication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load quantum data with original test set.\n",
    "x_train_q, y_train_q = utils.prepare_quantum_data(\n",
    "    x_train, y_train, \n",
    "    num_qubits=16,\n",
    "    a=3,\n",
    "    b=6,\n",
    "    invert=False)\n",
    "\n",
    "x_test_q, y_test_q = utils.prepare_quantum_data(\n",
    "    x_test, y_test,\n",
    "    num_qubits=16,\n",
    "    a=3,\n",
    "    b=6,\n",
    "    invert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a QNN (XX-ZZ) and evaluate it. The architecture of QNN is defined\n",
    "# as a list e.g.  ['XX', 'ZZ'],  ['XX', 'ZZ', 'XX'].\n",
    "arch = ['XX', 'ZZ']\n",
    "model = models.create_qnn(num_qubits=NUM_QUBITS, arch=arch)\n",
    "\n",
    "_ = model.fit(\n",
    "    x_train_q, y_train_q,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test_q, y_test_q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on the original test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.evaluate(x_test_q, y_test_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on the negational test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load quantum data with negational test set.\n",
    "x_train_q_inv, y_train_q_inv = utils.prepare_quantum_data(\n",
    "    x_train, y_train,\n",
    "    num_qubits=16,\n",
    "    a=3,\n",
    "    b=6,\n",
    "    invert=True)\n",
    "\n",
    "\n",
    "x_test_q_inv, y_test_q_inv = utils.prepare_quantum_data(\n",
    "    x_test, y_test,\n",
    "    num_qubits=16,\n",
    "    a=3,\n",
    "    b=6,\n",
    "    invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.evaluate(x_test_q_inv, y_test_q_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2 Evaluate negational symmetry numerically.\n",
    "\n",
    "#### Theorem 1 $f_{\\theta} (\\textbf{x}) = f_{\\theta} (\\tilde{\\textbf{x}})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we provide a pre-trained weights for QNN (XX-ZZ) for convenience. \n",
    "arch = ['XX', 'ZZ']\n",
    "model = models.create_qnn(num_qubits=NUM_QUBITS, arch=arch)\n",
    "weights = np.load('weights.npy')\n",
    "model.set_weights([weights])\n",
    "\n",
    "logits_ori = model(x_test_q, training=False)\n",
    "logits_neg = model(x_test_q_inv, training=False)\n",
    "\n",
    "logits_ori_np = logits_ori.numpy()\n",
    "logits_neg_np = logits_neg.numpy()\n",
    "\n",
    "diff = logits_ori_np - logits_neg_np\n",
    "\n",
    "print('mean: {}'.format(np.mean(diff)))\n",
    "print('std: {}'.format(np.std(diff)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theorem 2 $g_{\\theta} (\\textbf{x}) = g_{\\theta} (\\tilde{\\textbf{x}})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "model = models.create_qnn_feat(num_qubits=16, arch=['XX', 'ZZ'])\n",
    "weights = np.load('weights.npy')\n",
    "model.set_weights([weights])\n",
    "\n",
    "feats = model(x_test_q, training=False)\n",
    "feats_np = feats.numpy()\n",
    "feats_inv = model(x_test_q_inv, training=False)\n",
    "feats_inv_np = feats_inv.numpy()\n",
    "\n",
    "total_norm = 0\n",
    "r = []\n",
    "cos = []\n",
    "for i in range(len(x_test_q)):\n",
    "    total_norm += LA.norm(feats_np[i] + feats_inv_np[i])\n",
    "    r.append(pearsonr(feats_np[i], feats_inv_np[i]))\n",
    "    cos.append(1 - cosine(feats_np[i], feats_inv_np[i]))\n",
    "    \n",
    "print('total norm: {}'.format(total_norm))\n",
    "print('avg pearson r coefficients: {}'.format(np.mean(r)))\n",
    "print('avg cosine similarities: {}'.format(np.mean(cos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.3 t-SNE Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=0, perplexity=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE visualization of the original test set\n",
    "tsne_obj = tsne.fit_transform(feats_np)\n",
    "tsne_df = pd.DataFrame({'X': tsne_obj[:, 0],\n",
    "                        'Y': tsne_obj[:, 1],\n",
    "                        'Class': ((y_test_q + 1) // 2).astype(np.int)})\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=\"X\", y=\"Y\", hue=\"Class\", legend=\"full\", data=tsne_df)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE visualization of the negational test set\n",
    "tsne_inv_obj = tsne.fit_transform(feats_inv_np)\n",
    "tsne_inv_df = pd.DataFrame({'X': tsne_inv_obj[:, 0],\n",
    "                        'Y': tsne_inv_obj[:, 1],\n",
    "                        'Class': ((y_test_q + 1) // 2).astype(np.int)})\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=\"X\", y=\"Y\", hue=\"Class\", legend=\"full\", data=tsne_inv_df)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.4 Drawback of Negational Symmetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_q_2 = tf.concat([x_train_q, x_train_q_inv], 0)\n",
    "y_train_q_2 = np.concatenate([np.ones_like(y_train_q), -1 * np.ones_like(y_train_q_inv)], 0)\n",
    "\n",
    "x_test_q_2 = tf.concat([x_test_q, x_test_q_inv], 0)\n",
    "y_test_q_2 = np.concatenate([np.ones_like(y_test_q), -1 * np.ones_like(y_test_q_inv)], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = ['XX', 'ZZ']\n",
    "model = models.create_qnn(num_qubits=NUM_QUBITS, arch=arch)\n",
    "\n",
    "_ = model.fit(\n",
    "    x_train_q_2, y_train_q_2,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test_q_2, y_test_q_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Comparison with Classical Models.\n",
    "### Part 2.1 Compare with DNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load classical data with original test set.\n",
    "x_train_c, y_train_c = utils.prepare_classical_data(\n",
    "    x_train, y_train,\n",
    "    num_qubits=16,\n",
    "    a=3,\n",
    "    b=6,\n",
    "    invert=False)\n",
    "\n",
    "x_test_c, y_test_c = utils.prepare_classical_data(\n",
    "    x_test, y_test,\n",
    "    num_qubits=16,\n",
    "    a=3,\n",
    "    b=6,\n",
    "    invert=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a DNN and evaluate it.\n",
    "model = models.create_dnn(num_qubits=NUM_QUBITS)\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "_ = model.fit(\n",
    "    x_train_c, y_train_c,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test_c, y_test_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on the original test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.evaluate(x_test_c, y_test_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on the negational test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load classical data with negational test set.\n",
    "x_train_c_inv, y_train_c_inv = utils.prepare_classical_data(\n",
    "    x_train, y_train,\n",
    "    num_qubits=16,\n",
    "    a=3,\n",
    "    b=6,\n",
    "    invert=True)\n",
    "\n",
    "x_test_c_inv, y_test_c_inv = utils.prepare_classical_data(\n",
    "    x_test, y_test,\n",
    "    num_qubits=16,\n",
    "    a=3,\n",
    "    b=6,\n",
    "    invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.evaluate(x_test_c_inv, y_test_c_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2.2 Compare with CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.create_cnn(num_qubits=NUM_QUBITS)\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "_ = model.fit(\n",
    "    x_train_c, y_train_c,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test_c, y_test_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on the original test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.evaluate(x_test_c, y_test_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on the negational test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.evaluate(x_test_c_inv, y_test_c_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with SVMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "num_train = len(x_train_c)\n",
    "x_train_c_np = tf.reshape(x_train_c, [num_train, -1]).numpy()\n",
    "num_test = len(x_test_c)\n",
    "x_test_c_np = tf.reshape(x_test_c, [num_test, -1]).numpy()\n",
    "\n",
    "x_test_c_inv_np = tf.reshape(x_test_c_inv, [num_test, -1]).numpy()\n",
    "\n",
    "clf = svm.SVC(C=C, kernel='rbf')\n",
    "clf.fit(x_train_bin, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test_bin)\n",
    "print('Accuracy on the original test set: {}'.format(accuracy_score(y_test_c, y_pred)))\n",
    "  \n",
    "y_pred = clf.predict(x_test_bin_in)\n",
    "print('Accuracy on the negational test set: {}', accuracy_score(y_test_c_inv, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
