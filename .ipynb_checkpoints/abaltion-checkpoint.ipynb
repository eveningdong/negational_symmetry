{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_quantum as tfq\n",
    "print(tf.__version__)\n",
    "\n",
    "import cirq\n",
    "import sympy\n",
    "import numpy as np\n",
    "import collections\n",
    "import time\n",
    "\n",
    "# visualization tools\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from cirq.contrib.svg import SVGCircuit\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5\n",
    "\n",
    "def filter(x, y, a=3, b=6):\n",
    "    keep = (y == a) | (y == b)\n",
    "    x, y = x[keep], y[keep]\n",
    "    y = y == a\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def remove_ambiguous(xs, ys, a=3, b=6, verbal=False):\n",
    "    mapping = collections.defaultdict(set)\n",
    "    # Determine the set of labels for each unique image:\n",
    "    for x,y in zip(xs,ys):\n",
    "        mapping[tuple(x.flatten())].add(y)\n",
    "    \n",
    "    new_x = []\n",
    "    new_y = []\n",
    "    for x,y in zip(xs, ys):\n",
    "        labels = mapping[tuple(x.flatten())]\n",
    "        if len(labels) == 1:\n",
    "            new_x.append(x)\n",
    "            new_y.append(list(labels)[0])\n",
    "        else:\n",
    "            # Throw out images that match more than one label.\n",
    "            pass\n",
    "      \n",
    "    if verbal:\n",
    "        num_a = sum(1 for value in mapping.values() if True in value)\n",
    "        num_b = sum(1 for value in mapping.values() if False in value)\n",
    "        num_both = sum(1 for value in mapping.values() if len(value) == 2)\n",
    "\n",
    "        print(\"Number of unique images:\", len(mapping.values()))\n",
    "        print(\"Number of unique {}s: \".format(a), num_a)\n",
    "        print(\"Number of unique {}s: \".format(b), num_b)\n",
    "        print(\"Number of unique contradictory images: \", num_both)\n",
    "        \n",
    "        num = len(xs)\n",
    "        num_a = sum(ys)\n",
    "        num_b = num - num_a\n",
    "        print(\"Initial number of examples: \", num)\n",
    "        print(\"Number of {}s: \".format(a), num_a)\n",
    "        print(\"Number of {}s: \".format(b), num_b)\n",
    "    \n",
    "        num = len(new_x)\n",
    "        num_a = sum(new_y)\n",
    "        num_b = num - num_a\n",
    "        print(\"Remaining non-contradictory examples: \", num)\n",
    "        print(\"Number of non-contradictory {}s: \".format(a), num_a)\n",
    "        print(\"Number of non-contradictory {}s: \".format(b), num_b)\n",
    "        print()\n",
    "            \n",
    "    return np.array(new_x), np.array(new_y)\n",
    "\n",
    "\n",
    "def convert_to_circuit(image, h):\n",
    "    \"\"\"Encode truncated classical image into quantum datapoint.\"\"\"\n",
    "    values = np.ndarray.flatten(image)\n",
    "    qubits = cirq.GridQubit.rect(h, h)\n",
    "    circuit = cirq.Circuit()\n",
    "    for i, value in enumerate(values):\n",
    "        if value:\n",
    "            circuit.append(cirq.X(qubits[i]))\n",
    "    return circuit\n",
    "\n",
    "\n",
    "def get_edge(num_qubits):\n",
    "    h = int(np.sqrt(num_qubits))\n",
    "    assert h**2 == num_qubits, 'num_qubits is not a perfect square of an integer!'\n",
    "    return h\n",
    "\n",
    "\n",
    "def prepare_quantum_data(x, y, num_qubits, a=3, b=6, invert=False, verbal=False):\n",
    "    h = get_edge(num_qubits)\n",
    "    x = x[..., np.newaxis] / 255.0\n",
    "    x, y = filter(x, y, a, b)\n",
    "    x_small = tf.image.resize(x, (h, h)).numpy()\n",
    "\n",
    "    x_bin = np.array(x_small > THRESHOLD, dtype=np.float32)\n",
    "\n",
    "    x_nocon, y_nocon = remove_ambiguous(x_bin, y, a, b, verbal)\n",
    "\n",
    "    if invert:\n",
    "        x_nocon = 1 - x_nocon\n",
    "\n",
    "    x_circ = [convert_to_circuit(x, h) for x in x_nocon]\n",
    "    x_tfcirc = tfq.convert_to_tensor(x_circ)\n",
    "\n",
    "    y_nocon = 2.0*y_nocon-1.0\n",
    "\n",
    "    return x_tfcirc, y_nocon\n",
    "\n",
    "\n",
    "def prepare_classical_data(x, y, num_qubits, a=3, b=6, invert=False, verbal=False):\n",
    "    h = get_edge(num_qubits)\n",
    "    x = x[..., np.newaxis] / 255.0\n",
    "    x, y = filter(x, y, a, b)\n",
    "    x_small = tf.image.resize(x, (h, h)).numpy()\n",
    "\n",
    "    x_bin = np.array(x_small > THRESHOLD, dtype=np.float32)\n",
    "\n",
    "    x_nocon, y_nocon = remove_ambiguous(x_bin, y, a, b, verbal)\n",
    "\n",
    "    if invert:\n",
    "        x_nocon = 1 - x_nocon\n",
    "\n",
    "    return x_nocon, y_nocon\n",
    "\n",
    "\n",
    "def get_mnist_train(num_qubits, a, b, quantum=True, verbal=False):\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    if quantum:\n",
    "        x_train_tfcirc, y_train_hinge = prepare_quantum_data(x_train, y_train, \n",
    "                                                       num_qubits, a, b, verbal)\n",
    "        return x_train_tfcirc, y_train_hinge\n",
    "    else:\n",
    "        x_train_bin, y_train = prepare_classical_data(x_train, y_train, \n",
    "                                                      num_qubits, a, b, verbal)\n",
    "        return x_train_bin, y_train\n",
    "        \n",
    "\n",
    "def get_mnist_test(num_qubits, a, b, quantum=True, invert=True, verbal=False):\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    \n",
    "    if quantum:\n",
    "        x_test_tfcirc, y_test_hinge = prepare_quantum_data(x_test, y_test, \n",
    "                                                           num_qubits, a, b,\n",
    "                                                           invert=invert, verbal=False)\n",
    "        return x_test_tfcirc, y_test_hinge\n",
    "    else: \n",
    "        x_test_bin, y_test = prepare_classical_data(x_test, y_test, \n",
    "                                                    num_qubits, a, b,\n",
    "                                                    invert=invert, verbal=False)\n",
    "        return x_test_bin, y_test\n",
    "\n",
    "    \n",
    "def hinge_accuracy(y_true, y_pred):\n",
    "    y_true = tf.squeeze(y_true) > 0.0\n",
    "    y_pred = tf.squeeze(y_pred) > 0.0\n",
    "    result = tf.cast(y_true == y_pred, tf.float32)\n",
    "    return tf.reduce_mean(result)\n",
    "\n",
    "\n",
    "# callbacks = [\n",
    "#     tf.keras.callbacks.EarlyStoping(\n",
    "#     monitor='val_loss',\n",
    "#     min_delta=1e-2,\n",
    "#     patience=2,\n",
    "#     verbose=1,\n",
    "#     restore_best_weights=True,\n",
    "#     )\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircuitLayerBuilder():\n",
    "    def __init__(self, data_qubits, readout):\n",
    "        self.data_qubits = data_qubits\n",
    "        self.readout = readout\n",
    "    \n",
    "    def add_layer(self, circuit, gate, prefix):\n",
    "        for i, qubit in enumerate(self.data_qubits):\n",
    "            symbol = sympy.Symbol(prefix + '-' + str(i))\n",
    "            circuit.append(gate(qubit, self.readout)**symbol)\n",
    "\n",
    "\n",
    "def get_edge(num_qubits):\n",
    "    h = int(np.sqrt(num_qubits))\n",
    "    assert h**2 == num_qubits, 'num_qubits is not a perfect square of an integer!'\n",
    "    return h\n",
    "\n",
    "\n",
    "def create_quantum_model(num_qubits=16):\n",
    "    \"\"\"Create a QNN model circuit and readout operation to go along with it.\"\"\"\n",
    "    h = get_edge(num_qubits)\n",
    "    data_qubits = cirq.GridQubit.rect(h, h)  # a 4x4 grid.\n",
    "    readout = cirq.GridQubit(-1, -1)         # a single qubit at [-1,-1]\n",
    "    circuit = cirq.Circuit()\n",
    "    \n",
    "    # Prepare the readout qubit.\n",
    "    circuit.append(cirq.X(readout))\n",
    "    circuit.append(cirq.H(readout))\n",
    "    \n",
    "    builder = CircuitLayerBuilder(\n",
    "        data_qubits = data_qubits,\n",
    "        readout=readout)\n",
    "\n",
    "    # Then add layers (experiment by adding more).\n",
    "    builder.add_layer(circuit, cirq.XX, \"xx\")\n",
    "    builder.add_layer(circuit, cirq.ZZ, \"zz\")\n",
    "\n",
    "    # Finally, prepare the readout qubit.\n",
    "    circuit.append(cirq.H(readout))\n",
    "\n",
    "    return circuit, cirq.Z(readout)\n",
    "\n",
    "\n",
    "def create_fair_classical_model(num_qubits=16, model_name='dnn'):\n",
    "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
    "    h = get_edge(num_qubits)\n",
    "    model = tf.keras.Sequential(name=model_name)\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(h,h,1)))\n",
    "    model.add(tf.keras.layers.Dense(2, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"779.0165625000001\" height=\"200.0\"><line x1=\"39.810625\" x2=\"749.0165625000001\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"749.0165625000001\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"749.0165625000001\" y1=\"125.0\" y2=\"125.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"749.0165625000001\" y1=\"175.0\" y2=\"175.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"184.62390625\" x2=\"184.62390625\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"274.62921875\" x2=\"274.62921875\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"364.63453125\" x2=\"364.63453125\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"454.53375000000005\" x2=\"454.53375000000005\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"544.326875\" x2=\"544.326875\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"634.12\" x2=\"634.12\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">(-1, -1): </text><rect x=\"10.0\" y=\"55.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">(0, 0): </text><rect x=\"10.0\" y=\"105.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">(0, 1): </text><rect x=\"10.0\" y=\"155.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">(0, 2): </text><rect x=\"89.62125\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"109.62125\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\">H</text><rect x=\"149.62125\" y=\"55.0\" width=\"70.0053125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"184.62390625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">XX^(θ₁₁)</text><rect x=\"149.62125\" y=\"5.0\" width=\"70.0053125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"184.62390625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">XX</text><rect x=\"239.6265625\" y=\"105.0\" width=\"70.0053125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"274.62921875\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">XX^(θ₁₂)</text><rect x=\"239.6265625\" y=\"5.0\" width=\"70.0053125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"274.62921875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">XX</text><rect x=\"329.63187500000004\" y=\"155.0\" width=\"70.0053125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"364.63453125\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">XX^(θ₁₃)</text><rect x=\"329.63187500000004\" y=\"5.0\" width=\"70.0053125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"364.63453125\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">XX</text><rect x=\"419.63718750000004\" y=\"55.0\" width=\"69.793125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"454.53375000000005\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">ZZ^(θ₂₁)</text><rect x=\"419.63718750000004\" y=\"5.0\" width=\"69.793125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"454.53375000000005\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">ZZ</text><rect x=\"509.43031249999996\" y=\"105.0\" width=\"69.793125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"544.326875\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">ZZ^(θ₂₂)</text><rect x=\"509.43031249999996\" y=\"5.0\" width=\"69.793125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"544.326875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">ZZ</text><rect x=\"599.2234375\" y=\"155.0\" width=\"69.793125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"634.12\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">ZZ^(θ₂₃)</text><rect x=\"599.2234375\" y=\"5.0\" width=\"69.793125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"634.12\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">ZZ</text><rect x=\"689.0165625000001\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"709.0165625000001\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\">H</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x7f355eb14198>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VisualCircuitLayerBuilder():\n",
    "    def __init__(self, data_qubits, readout):\n",
    "        self.data_qubits = data_qubits\n",
    "        self.readout = readout\n",
    "    \n",
    "    def add_layer(self, circuit, gate, prefix):\n",
    "        for i, qubit in enumerate(self.data_qubits):\n",
    "            symbol = sympy.Symbol(prefix + str(i+1).translate(subscript))\n",
    "            circuit.append(gate(qubit, self.readout)**symbol)\n",
    "\n",
    "\n",
    "def visual_quantum_model(num_qubits=4):\n",
    "    \"\"\"Create a QNN model circuit and readout operation to go along with it.\"\"\"\n",
    "    data_qubits = cirq.GridQubit.rect(1, num_qubits)  \n",
    "    readout = cirq.GridQubit(-1, -1)         # a single qubit at [-1,-1]\n",
    "    circuit = cirq.Circuit()\n",
    "    \n",
    "    # Prepare the readout qubit.\n",
    "#     circuit.append(cirq.X(readout))\n",
    "    circuit.append(cirq.H(readout))\n",
    "    \n",
    "    builder = VisualCircuitLayerBuilder(\n",
    "        data_qubits = data_qubits,\n",
    "        readout=readout)\n",
    "\n",
    "    # Then add layers (experiment by adding more).\n",
    "    builder.add_layer(circuit, cirq.XX, u'\\u03B8' + '1'.translate(subscript))\n",
    "    builder.add_layer(circuit, cirq.ZZ, u'\\u03B8' + '2'.translate(subscript))\n",
    "\n",
    "    # Finally, prepare the readout qubit.\n",
    "    circuit.append(cirq.H(readout))\n",
    "    return circuit\n",
    "\n",
    "subscript = str.maketrans(\"0123456789\", \"₀₁₂₃₄₅₆₇₈₉\")\n",
    "circuit = visual_quantum_model(num_qubits=3)\n",
    "SVGCircuit(circuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3649 samples, validate on 890 samples\n",
      "Epoch 1/8\n",
      "3649/3649 [==============================] - 494s 135ms/sample - loss: 0.9720 - hinge_accuracy: 0.6204 - val_loss: 1.0293 - val_hinge_accuracy: 0.4434\n",
      "Epoch 2/8\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.7519 - hinge_accuracy: 0.7272 - val_loss: 0.5953 - val_hinge_accuracy: 0.8269\n",
      "Epoch 3/8\n",
      "3649/3649 [==============================] - 491s 135ms/sample - loss: 0.2797 - hinge_accuracy: 0.9291 - val_loss: 0.1604 - val_hinge_accuracy: 0.9448\n",
      "Epoch 4/8\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.1340 - hinge_accuracy: 0.9421 - val_loss: 0.1169 - val_hinge_accuracy: 0.9448\n",
      "Epoch 5/8\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.1154 - hinge_accuracy: 0.9421 - val_loss: 0.1201 - val_hinge_accuracy: 0.9448\n",
      "Epoch 6/8\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.1025 - hinge_accuracy: 0.9421 - val_loss: 0.1300 - val_hinge_accuracy: 0.9448\n",
      "Epoch 7/8\n",
      "3649/3649 [==============================] - 491s 135ms/sample - loss: 0.0814 - hinge_accuracy: 0.9625 - val_loss: 0.1366 - val_hinge_accuracy: 0.9573\n",
      "Epoch 8/8\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.0646 - hinge_accuracy: 0.9660 - val_loss: 0.1555 - val_hinge_accuracy: 0.9562\n",
      "The training time for 5 epochs is 3935.9123170375824\n",
      "890/890 [==============================] - 4s 4ms/sample - loss: 0.1555 - hinge_accuracy: 0.9562\n"
     ]
    }
   ],
   "source": [
    "# QNN\n",
    "x_train_tfcirc, y_train_hinge = get_mnist_train(16, a=3, b=6)\n",
    "x_test_tfcirc, y_test_hinge = get_mnist_test(16, a=3, b=6, invert=False)\n",
    "\n",
    "model_circuit, model_readout = create_quantum_model(num_qubits=16)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
    "        tfq.layers.PQC(model_circuit, model_readout),\n",
    "        ], name='qnn')\n",
    "\n",
    "model.compile(\n",
    "        loss=tf.keras.losses.Hinge(),\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=[hinge_accuracy])\n",
    "\n",
    "start = time.time()\n",
    "qnn_history = model.fit(\n",
    "        x_train_tfcirc, y_train_hinge,\n",
    "        batch_size=32,\n",
    "        epochs=8,\n",
    "        verbose=1,\n",
    "#         callbacks=callbacks,\n",
    "        validation_data=(x_test_tfcirc, y_test_hinge))\n",
    "end = time.time()\n",
    "print('The training time is {}'.format(end - start))\n",
    "\n",
    "qnn_results = model.evaluate(x_test_tfcirc, y_test_hinge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3649 samples, validate on 890 samples\n",
      "Epoch 1/8\n",
      "3649/3649 [==============================] - 493s 135ms/sample - loss: 0.9703 - hinge_accuracy: 0.6122 - val_loss: 0.8567 - val_hinge_accuracy: 0.8788\n",
      "Epoch 2/8\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.5504 - hinge_accuracy: 0.8609 - val_loss: 0.3952 - val_hinge_accuracy: 0.8983\n",
      "Epoch 3/8\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.2662 - hinge_accuracy: 0.9022 - val_loss: 0.2667 - val_hinge_accuracy: 0.9105\n",
      "Epoch 4/8\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.1736 - hinge_accuracy: 0.9378 - val_loss: 0.2729 - val_hinge_accuracy: 0.9329\n",
      "Epoch 5/8\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.1257 - hinge_accuracy: 0.9666 - val_loss: 0.2927 - val_hinge_accuracy: 0.9749\n",
      "Epoch 6/8\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.0964 - hinge_accuracy: 0.9810 - val_loss: 0.3254 - val_hinge_accuracy: 0.9749\n",
      "Epoch 7/8\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.0759 - hinge_accuracy: 0.9845 - val_loss: 0.3288 - val_hinge_accuracy: 0.9783\n",
      "Epoch 8/8\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.0590 - hinge_accuracy: 0.9848 - val_loss: 0.3315 - val_hinge_accuracy: 0.8328\n",
      "The training time for 5 epochs is 3936.78120803833\n",
      "890/890 [==============================] - 4s 4ms/sample - loss: 0.3315 - hinge_accuracy: 0.8328\n"
     ]
    }
   ],
   "source": [
    "## QNN Domain Adaptation\n",
    "x_train_tfcirc, y_train_hinge = get_mnist_train(16, a=3, b=6)\n",
    "x_test_tfcirc, y_test_hinge = get_mnist_test(16, a=3, b=6)\n",
    "\n",
    "model_circuit, model_readout = create_quantum_model(num_qubits=16)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
    "        tfq.layers.PQC(model_circuit, model_readout),\n",
    "        ], name='qnn_da')\n",
    "\n",
    "model.compile(\n",
    "        loss=tf.keras.losses.Hinge(),\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=[hinge_accuracy])\n",
    "\n",
    "start = time.time()\n",
    "qnn_history = model.fit(\n",
    "        x_train_tfcirc, y_train_hinge,\n",
    "        batch_size=32,\n",
    "        epochs=8,\n",
    "        verbose=1,\n",
    "#         callbacks=callbacks,\n",
    "        validation_data=(x_test_tfcirc, y_test_hinge))\n",
    "end = time.time()\n",
    "print('The training time for 5 epochs is {}'.format(end - start))\n",
    "\n",
    "qnn_results = model.evaluate(x_test_tfcirc, y_test_hinge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep QNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deep_quantum_model(num_qubits=16):\n",
    "    \"\"\"Create a QNN model circuit and readout operation to go along with it.\"\"\"\n",
    "    h = get_edge(num_qubits)\n",
    "    data_qubits = cirq.GridQubit.rect(h, h)  # a 4x4 grid.\n",
    "    readout = cirq.GridQubit(-1, -1)         # a single qubit at [-1,-1]\n",
    "    circuit = cirq.Circuit()\n",
    "    \n",
    "    # Prepare the readout qubit.\n",
    "    circuit.append(cirq.X(readout))\n",
    "    circuit.append(cirq.H(readout))\n",
    "    \n",
    "    builder = CircuitLayerBuilder(\n",
    "        data_qubits = data_qubits,\n",
    "        readout=readout)\n",
    "\n",
    "    # Then add layers (experiment by adding more).\n",
    "    builder.add_layer(circuit, cirq.XX, \"xx1\")\n",
    "    builder.add_layer(circuit, cirq.ZZ, \"zz1\")\n",
    "    builder.add_layer(circuit, cirq.XX, \"xx2\")\n",
    "\n",
    "    # Finally, prepare the readout qubit.\n",
    "    circuit.append(cirq.H(readout))\n",
    "\n",
    "    return circuit, cirq.Z(readout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3649 samples, validate on 890 samples\n",
      "Epoch 1/8\n",
      "3649/3649 [==============================] - 935s 256ms/sample - loss: 1.0000 - hinge_accuracy: 0.5418 - val_loss: 0.9987 - val_hinge_accuracy: 0.7163\n",
      "Epoch 2/8\n",
      "3649/3649 [==============================] - 937s 257ms/sample - loss: 0.7824 - hinge_accuracy: 0.7897 - val_loss: 0.4169 - val_hinge_accuracy: 0.8652\n",
      "Epoch 3/8\n",
      "3649/3649 [==============================] - 934s 256ms/sample - loss: 0.2320 - hinge_accuracy: 0.9130 - val_loss: 0.1709 - val_hinge_accuracy: 0.9491\n",
      "Epoch 4/8\n",
      "3649/3649 [==============================] - 937s 257ms/sample - loss: 0.1068 - hinge_accuracy: 0.9837 - val_loss: 0.1220 - val_hinge_accuracy: 0.9674\n",
      "Epoch 5/8\n",
      "3649/3649 [==============================] - 934s 256ms/sample - loss: 0.0792 - hinge_accuracy: 0.9908 - val_loss: 0.1328 - val_hinge_accuracy: 0.9718\n",
      "Epoch 6/8\n",
      "3649/3649 [==============================] - 935s 256ms/sample - loss: 0.0675 - hinge_accuracy: 0.9899 - val_loss: 0.1489 - val_hinge_accuracy: 0.9663\n",
      "Epoch 7/8\n",
      "3649/3649 [==============================] - 934s 256ms/sample - loss: 0.0549 - hinge_accuracy: 0.9927 - val_loss: 0.1721 - val_hinge_accuracy: 0.9696\n",
      "Epoch 8/8\n",
      "3649/3649 [==============================] - 934s 256ms/sample - loss: 0.0499 - hinge_accuracy: 0.9943 - val_loss: 0.1985 - val_hinge_accuracy: 0.9674\n",
      "The training time for 5 epochs is 7481.2576105594635\n",
      "890/890 [==============================] - 5s 6ms/sample - loss: 0.1985 - hinge_accuracy: 0.9674\n"
     ]
    }
   ],
   "source": [
    "## Deep QNN\n",
    "x_train_tfcirc, y_train_hinge = get_mnist_train(16, a=3, b=6)\n",
    "x_test_tfcirc, y_test_hinge = get_mnist_test(16, a=3, b=6, invert=False)\n",
    "\n",
    "try:\n",
    "    del model_circuit, model_readout, model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model_circuit, model_readout = create_deep_quantum_model(num_qubits=16)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
    "        tfq.layers.PQC(model_circuit, model_readout),\n",
    "        ], name='deep_qnn')\n",
    "\n",
    "model.compile(\n",
    "        loss=tf.keras.losses.Hinge(),\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=[hinge_accuracy])\n",
    "\n",
    "start = time.time()\n",
    "qnn_history = model.fit(\n",
    "        x_train_tfcirc, y_train_hinge,\n",
    "        batch_size=32,\n",
    "        epochs=8,\n",
    "        verbose=1,\n",
    "#         callbacks=callbacks,\n",
    "        validation_data=(x_test_tfcirc, y_test_hinge))\n",
    "end = time.time()\n",
    "print('The training time is {}'.format(end - start))\n",
    "\n",
    "qnn_results = model.evaluate(x_test_tfcirc, y_test_hinge) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3649 samples, validate on 890 samples\n",
      "Epoch 1/8\n",
      "3649/3649 [==============================] - 934s 256ms/sample - loss: 0.9128 - hinge_accuracy: 0.7484 - val_loss: 0.6954 - val_hinge_accuracy: 0.8547\n",
      "Epoch 2/8\n",
      "3649/3649 [==============================] - 933s 256ms/sample - loss: 0.4961 - hinge_accuracy: 0.8666 - val_loss: 0.2741 - val_hinge_accuracy: 0.9245\n",
      "Epoch 3/8\n",
      "3649/3649 [==============================] - 933s 256ms/sample - loss: 0.1804 - hinge_accuracy: 0.9622 - val_loss: 0.1217 - val_hinge_accuracy: 0.9590\n",
      "Epoch 4/8\n",
      "3649/3649 [==============================] - 933s 256ms/sample - loss: 0.0899 - hinge_accuracy: 0.9647 - val_loss: 0.0921 - val_hinge_accuracy: 0.9602\n",
      "Epoch 5/8\n",
      "3649/3649 [==============================] - 933s 256ms/sample - loss: 0.0748 - hinge_accuracy: 0.9660 - val_loss: 0.0882 - val_hinge_accuracy: 0.9602\n",
      "Epoch 6/8\n",
      "3649/3649 [==============================] - 933s 256ms/sample - loss: 0.0715 - hinge_accuracy: 0.9674 - val_loss: 0.0876 - val_hinge_accuracy: 0.9602\n",
      "Epoch 7/8\n",
      "3649/3649 [==============================] - 933s 256ms/sample - loss: 0.0697 - hinge_accuracy: 0.9685 - val_loss: 0.0859 - val_hinge_accuracy: 0.9602\n",
      "Epoch 8/8\n",
      "3649/3649 [==============================] - 933s 256ms/sample - loss: 0.0683 - hinge_accuracy: 0.9685 - val_loss: 0.0857 - val_hinge_accuracy: 0.9602\n",
      "The training time is 7465.877643585205\n",
      "890/890 [==============================] - 5s 6ms/sample - loss: 0.0857 - hinge_accuracy: 0.9602\n"
     ]
    }
   ],
   "source": [
    "## Deep QNN Domain Adaptation\n",
    "x_train_tfcirc, y_train_hinge = get_mnist_train(16, a=3, b=6)\n",
    "x_test_tfcirc, y_test_hinge = get_mnist_test(16, a=3, b=6)\n",
    "\n",
    "try:\n",
    "    del model_circuit, model_readout, model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model_circuit, model_readout = create_deep_quantum_model(num_qubits=16)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
    "        tfq.layers.PQC(model_circuit, model_readout),\n",
    "        ], name='deep_qnn_da')\n",
    "\n",
    "model.compile(\n",
    "        loss=tf.keras.losses.Hinge(),\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=[hinge_accuracy])\n",
    "\n",
    "start = time.time()\n",
    "qnn_history = model.fit(\n",
    "        x_train_tfcirc, y_train_hinge,\n",
    "        batch_size=32,\n",
    "        epochs=8,\n",
    "        verbose=1,\n",
    "#         callbacks=callbacks,\n",
    "        validation_data=(x_test_tfcirc, y_test_hinge))\n",
    "end = time.time()\n",
    "print('The training time is {}'.format(end - start))\n",
    "\n",
    "qnn_results = model.evaluate(x_test_tfcirc, y_test_hinge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deeper QNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deeper_quantum_model(num_qubits=16):\n",
    "    \"\"\"Create a QNN model circuit and readout operation to go along with it.\"\"\"\n",
    "    h = get_edge(num_qubits)\n",
    "    data_qubits = cirq.GridQubit.rect(h, h)  # a 4x4 grid.\n",
    "    readout = cirq.GridQubit(-1, -1)         # a single qubit at [-1,-1]\n",
    "    circuit = cirq.Circuit()\n",
    "    \n",
    "    # Prepare the readout qubit.\n",
    "    circuit.append(cirq.X(readout))\n",
    "    circuit.append(cirq.H(readout))\n",
    "    \n",
    "    builder = CircuitLayerBuilder(\n",
    "        data_qubits = data_qubits,\n",
    "        readout=readout)\n",
    "\n",
    "    # Then add layers (experiment by adding more).\n",
    "    builder.add_layer(circuit, cirq.XX, \"xx1\")\n",
    "    builder.add_layer(circuit, cirq.ZZ, \"zz1\")\n",
    "    builder.add_layer(circuit, cirq.XX, \"xx2\")\n",
    "    builder.add_layer(circuit, cirq.ZZ, \"zz2\")\n",
    "\n",
    "    # Finally, prepare the readout qubit.\n",
    "    circuit.append(cirq.H(readout))\n",
    "\n",
    "    return circuit, cirq.Z(readout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3649 samples, validate on 890 samples\n",
      "Epoch 1/12\n",
      "3649/3649 [==============================] - 1510s 414ms/sample - loss: 0.6001 - hinge_accuracy: 0.9125 - val_loss: 0.2016 - val_hinge_accuracy: 0.9855\n",
      "Epoch 2/12\n",
      "3649/3649 [==============================] - 1506s 413ms/sample - loss: 0.1092 - hinge_accuracy: 0.9859 - val_loss: 0.1158 - val_hinge_accuracy: 0.9651\n",
      "Epoch 3/12\n",
      "3649/3649 [==============================] - 1507s 413ms/sample - loss: 0.0618 - hinge_accuracy: 0.9780 - val_loss: 0.1378 - val_hinge_accuracy: 0.9651\n",
      "Epoch 4/12\n",
      "3649/3649 [==============================] - 1506s 413ms/sample - loss: 0.0554 - hinge_accuracy: 0.9772 - val_loss: 0.1312 - val_hinge_accuracy: 0.9651\n",
      "Epoch 5/12\n",
      "2304/3649 [=================>............] - ETA: 9:13 - loss: 0.0570 - hinge_accuracy: 0.9740"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3d14e770d24c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         validation_data=(x_test_tfcirc, y_test_hinge))\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The training time is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Deeper QNN\n",
    "x_train_tfcirc, y_train_hinge = get_mnist_train(16, a=3, b=6)\n",
    "x_test_tfcirc, y_test_hinge = get_mnist_test(16, a=3, b=6, invert=False)\n",
    "\n",
    "try:\n",
    "    del model_circuit, model_readout, model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model_circuit, model_readout = create_deeper_quantum_model(num_qubits=16)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
    "        tfq.layers.PQC(model_circuit, model_readout),\n",
    "        ], name='deeper_qnn')\n",
    "\n",
    "model.compile(\n",
    "        loss=tf.keras.losses.Hinge(),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.002),\n",
    "        metrics=[hinge_accuracy])\n",
    "\n",
    "start = time.time()\n",
    "qnn_history = model.fit(\n",
    "        x_train_tfcirc, y_train_hinge,\n",
    "        batch_size=32,\n",
    "        epochs=12,\n",
    "        verbose=1,\n",
    "#         callbacks=callbacks,\n",
    "        validation_data=(x_test_tfcirc, y_test_hinge))\n",
    "end = time.time()\n",
    "print('The training time is {}'.format(end - start))\n",
    "\n",
    "deeper_qnn_results = model.evaluate(x_test_tfcirc, y_test_hinge) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3649 samples, validate on 890 samples\n",
      "Epoch 1/12\n",
      "3649/3649 [==============================] - 1511s 414ms/sample - loss: 0.9122 - hinge_accuracy: 0.7527 - val_loss: 0.9547 - val_hinge_accuracy: 0.5813\n",
      "Epoch 2/12\n",
      "3649/3649 [==============================] - 1509s 413ms/sample - loss: 0.5388 - hinge_accuracy: 0.9125 - val_loss: 0.6062 - val_hinge_accuracy: 0.6720\n",
      "Epoch 3/12\n",
      "3649/3649 [==============================] - 1509s 414ms/sample - loss: 0.0786 - hinge_accuracy: 0.9758 - val_loss: 0.3597 - val_hinge_accuracy: 0.7236\n",
      "Epoch 4/12\n",
      "3649/3649 [==============================] - 1510s 414ms/sample - loss: 0.0478 - hinge_accuracy: 0.9929 - val_loss: 0.2942 - val_hinge_accuracy: 0.9900\n",
      "Epoch 5/12\n",
      "3649/3649 [==============================] - 1509s 413ms/sample - loss: 0.0431 - hinge_accuracy: 0.9943 - val_loss: 0.3027 - val_hinge_accuracy: 0.9922\n",
      "Epoch 6/12\n",
      "3649/3649 [==============================] - 1510s 414ms/sample - loss: 0.0420 - hinge_accuracy: 0.9962 - val_loss: 0.2898 - val_hinge_accuracy: 0.9922\n",
      "Epoch 7/12\n",
      "1888/3649 [==============>...............] - ETA: 12:05 - loss: 0.0383 - hinge_accuracy: 0.9995"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-daf6bffbb844>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         validation_data=(x_test_tfcirc, y_test_hinge))\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The training time is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Deeper QNN Domain Adaptation\n",
    "x_train_tfcirc, y_train_hinge = get_mnist_train(16, a=3, b=6)\n",
    "x_test_tfcirc, y_test_hinge = get_mnist_test(16, a=3, b=6)\n",
    "\n",
    "try:\n",
    "    del model_circuit, model_readout, model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model_circuit, model_readout = create_deeper_quantum_model(num_qubits=16)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
    "        tfq.layers.PQC(model_circuit, model_readout),\n",
    "        ], name='deeper_qnn_da')\n",
    "\n",
    "model.compile(\n",
    "        loss=tf.keras.losses.Hinge(),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.002),\n",
    "        metrics=[hinge_accuracy])\n",
    "\n",
    "start = time.time()\n",
    "qnn_history = model.fit(\n",
    "        x_train_tfcirc, y_train_hinge,\n",
    "        batch_size=32,\n",
    "        epochs=12,\n",
    "        verbose=1,\n",
    "#         callbacks=callbacks,\n",
    "        validation_data=(x_test_tfcirc, y_test_hinge))\n",
    "end = time.time()\n",
    "print('The training time is {}'.format(end - start))\n",
    "\n",
    "deeper_qnn_results = model.evaluate(x_test_tfcirc, y_test_hinge) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle QNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shuffle_quantum_model(num_qubits=16):\n",
    "    \"\"\"Create a QNN model circuit and readout operation to go along with it.\"\"\"\n",
    "    h = get_edge(num_qubits)\n",
    "    data_qubits = cirq.GridQubit.rect(h, h)  # a 4x4 grid.\n",
    "    readout = cirq.GridQubit(-1, -1)         # a single qubit at [-1,-1]\n",
    "    circuit = cirq.Circuit()\n",
    "    \n",
    "    # Prepare the readout qubit.\n",
    "    circuit.append(cirq.X(readout))\n",
    "    circuit.append(cirq.H(readout))\n",
    "    \n",
    "    builder = CircuitLayerBuilder(\n",
    "        data_qubits = data_qubits,\n",
    "        readout=readout)\n",
    "\n",
    "    # Then add layers (experiment by adding more).\n",
    "    builder.add_layer(circuit, cirq.ZZ, \"zz\")\n",
    "    builder.add_layer(circuit, cirq.XX, \"xx\")\n",
    "    \n",
    "    # Finally, prepare the readout qubit.\n",
    "    circuit.append(cirq.H(readout))\n",
    "\n",
    "    return circuit, cirq.Z(readout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3649 samples, validate on 890 samples\n",
      "Epoch 1/12\n",
      "3649/3649 [==============================] - 493s 135ms/sample - loss: 0.8285 - hinge_accuracy: 0.5921 - val_loss: 0.5864 - val_hinge_accuracy: 0.8128\n",
      "Epoch 2/12\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.4732 - hinge_accuracy: 0.8519 - val_loss: 0.3458 - val_hinge_accuracy: 0.8874\n",
      "Epoch 3/12\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.2843 - hinge_accuracy: 0.8886 - val_loss: 0.2427 - val_hinge_accuracy: 0.9097\n",
      "Epoch 4/12\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.2183 - hinge_accuracy: 0.9022 - val_loss: 0.2192 - val_hinge_accuracy: 0.9097\n",
      "Epoch 5/12\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.1986 - hinge_accuracy: 0.9030 - val_loss: 0.2043 - val_hinge_accuracy: 0.9097\n",
      "Epoch 6/12\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.1879 - hinge_accuracy: 0.9030 - val_loss: 0.1843 - val_hinge_accuracy: 0.9097\n",
      "Epoch 7/12\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.1685 - hinge_accuracy: 0.9052 - val_loss: 0.1593 - val_hinge_accuracy: 0.9208\n",
      "Epoch 8/12\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.1318 - hinge_accuracy: 0.9416 - val_loss: 0.1426 - val_hinge_accuracy: 0.9548\n",
      "Epoch 9/12\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.0895 - hinge_accuracy: 0.9682 - val_loss: 0.1446 - val_hinge_accuracy: 0.9596\n",
      "Epoch 10/12\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.0627 - hinge_accuracy: 0.9715 - val_loss: 0.1476 - val_hinge_accuracy: 0.9607\n",
      "Epoch 11/12\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.0502 - hinge_accuracy: 0.9647 - val_loss: 0.1536 - val_hinge_accuracy: 0.9629\n",
      "Epoch 12/12\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.0456 - hinge_accuracy: 0.9889 - val_loss: 0.1657 - val_hinge_accuracy: 0.9707\n",
      "The training time for 8 epochs is 5906.829569339752\n",
      "890/890 [==============================] - 4s 4ms/sample - loss: 0.1657 - hinge_accuracy: 0.9707\n"
     ]
    }
   ],
   "source": [
    "## Shuffle QNN\n",
    "x_train_tfcirc, y_train_hinge = get_mnist_train(16, a=3, b=6)\n",
    "x_test_tfcirc, y_test_hinge = get_mnist_test(16, a=3, b=6, invert=False)\n",
    "\n",
    "try:\n",
    "    del model_circuit, model_readout, model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model_circuit, model_readout = create_shuffle_quantum_model(num_qubits=16)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
    "        tfq.layers.PQC(model_circuit, model_readout),\n",
    "        ], name='shuffle_qnn')\n",
    "\n",
    "model.compile(\n",
    "        loss=tf.keras.losses.Hinge(),\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=[hinge_accuracy])\n",
    "\n",
    "start = time.time()\n",
    "qnn_history = model.fit(\n",
    "        x_train_tfcirc, y_train_hinge,\n",
    "        batch_size=32,\n",
    "        epochs=12,\n",
    "        verbose=1,\n",
    "#         callbacks=callbacks,\n",
    "        validation_data=(x_test_tfcirc, y_test_hinge))\n",
    "end = time.time()\n",
    "print('The training time for 8 epochs is {}'.format(end - start))\n",
    "\n",
    "shuffle_qnn_results = model.evaluate(x_test_tfcirc, y_test_hinge) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3649 samples, validate on 890 samples\n",
      "Epoch 1/20\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.6866 - hinge_accuracy: 0.6870 - val_loss: 0.9261 - val_hinge_accuracy: 0.4736\n",
      "Epoch 2/20\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.5705 - hinge_accuracy: 0.7315 - val_loss: 0.7677 - val_hinge_accuracy: 0.5221\n",
      "Epoch 3/20\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.4655 - hinge_accuracy: 0.8011 - val_loss: 0.5920 - val_hinge_accuracy: 0.8377\n",
      "Epoch 4/20\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.3414 - hinge_accuracy: 0.8750 - val_loss: 0.3958 - val_hinge_accuracy: 0.8835\n",
      "Epoch 5/20\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.2341 - hinge_accuracy: 0.9171 - val_loss: 0.2534 - val_hinge_accuracy: 0.9256\n",
      "Epoch 6/20\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.1666 - hinge_accuracy: 0.9356 - val_loss: 0.1776 - val_hinge_accuracy: 0.9490\n",
      "Epoch 7/20\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.1280 - hinge_accuracy: 0.9554 - val_loss: 0.1346 - val_hinge_accuracy: 0.9501\n",
      "Epoch 8/20\n",
      "3649/3649 [==============================] - 491s 135ms/sample - loss: 0.1049 - hinge_accuracy: 0.9571 - val_loss: 0.1129 - val_hinge_accuracy: 0.9501\n",
      "Epoch 9/20\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.0904 - hinge_accuracy: 0.9571 - val_loss: 0.1031 - val_hinge_accuracy: 0.9501\n",
      "Epoch 10/20\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.0816 - hinge_accuracy: 0.9571 - val_loss: 0.0989 - val_hinge_accuracy: 0.9501\n",
      "Epoch 11/20\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.0753 - hinge_accuracy: 0.9636 - val_loss: 0.0987 - val_hinge_accuracy: 0.9593\n",
      "Epoch 12/20\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.0703 - hinge_accuracy: 0.9698 - val_loss: 0.1005 - val_hinge_accuracy: 0.9618\n",
      "Epoch 13/20\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.0659 - hinge_accuracy: 0.9723 - val_loss: 0.0997 - val_hinge_accuracy: 0.9629\n",
      "Epoch 14/20\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.0620 - hinge_accuracy: 0.9723 - val_loss: 0.1021 - val_hinge_accuracy: 0.9629\n",
      "Epoch 15/20\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.0587 - hinge_accuracy: 0.9723 - val_loss: 0.1079 - val_hinge_accuracy: 0.9629\n",
      "Epoch 16/20\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.0562 - hinge_accuracy: 0.9723 - val_loss: 0.1131 - val_hinge_accuracy: 0.9629\n",
      "Epoch 17/20\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.0542 - hinge_accuracy: 0.9720 - val_loss: 0.1092 - val_hinge_accuracy: 0.9629\n",
      "Epoch 18/20\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.0528 - hinge_accuracy: 0.9717 - val_loss: 0.1247 - val_hinge_accuracy: 0.9618\n",
      "Epoch 19/20\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.0519 - hinge_accuracy: 0.9712 - val_loss: 0.1237 - val_hinge_accuracy: 0.9618\n",
      "Epoch 20/20\n",
      "3649/3649 [==============================] - 492s 135ms/sample - loss: 0.0511 - hinge_accuracy: 0.9712 - val_loss: 0.1326 - val_hinge_accuracy: 0.9618\n",
      "The training time is 9839.407487154007\n",
      "890/890 [==============================] - 4s 4ms/sample - loss: 0.1326 - hinge_accuracy: 0.9618\n"
     ]
    }
   ],
   "source": [
    "## Shuffle QNN Domain Adaptation\n",
    "x_train_tfcirc, y_train_hinge = get_mnist_train(16, a=3, b=6)\n",
    "x_test_tfcirc, y_test_hinge = get_mnist_test(16, a=3, b=6)\n",
    "\n",
    "try:\n",
    "    del model_circuit, model_readout, model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model_circuit, model_readout = create_shuffle_quantum_model(num_qubits=16)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
    "        tfq.layers.PQC(model_circuit, model_readout),\n",
    "        ], name='shuffle_qnn_da')\n",
    "\n",
    "model.compile(\n",
    "        loss=tf.keras.losses.Hinge(),\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=[hinge_accuracy])\n",
    "\n",
    "start = time.time()\n",
    "qnn_history = model.fit(\n",
    "        x_train_tfcirc, y_train_hinge,\n",
    "        batch_size=32,\n",
    "        epochs=20,\n",
    "        verbose=1,\n",
    "#         callbacks=callbacks,\n",
    "        validation_data=(x_test_tfcirc, y_test_hinge))\n",
    "end = time.time()\n",
    "print('The training time is {}'.format(end - start))\n",
    "\n",
    "shuffle_qnn_results = model.evaluate(x_test_tfcirc, y_test_hinge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle Deep QNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shuffle_deep_quantum_model(num_qubits=16):\n",
    "    \"\"\"Create a QNN model circuit and readout operation to go along with it.\"\"\"\n",
    "    h = get_edge(num_qubits)\n",
    "    data_qubits = cirq.GridQubit.rect(h, h)  # a 4x4 grid.\n",
    "    readout = cirq.GridQubit(-1, -1)         # a single qubit at [-1,-1]\n",
    "    circuit = cirq.Circuit()\n",
    "    \n",
    "    # Prepare the readout qubit.\n",
    "    circuit.append(cirq.X(readout))\n",
    "    circuit.append(cirq.H(readout))\n",
    "    \n",
    "    builder = CircuitLayerBuilder(\n",
    "        data_qubits = data_qubits,\n",
    "        readout=readout)\n",
    "\n",
    "    # Then add layers (experiment by adding more).\n",
    "    builder.add_layer(circuit, cirq.ZZ, \"zz1\")\n",
    "    builder.add_layer(circuit, cirq.XX, \"xx1\")\n",
    "    builder.add_layer(circuit, cirq.ZZ, \"zz2\")\n",
    "    \n",
    "    # Finally, prepare the readout qubit.\n",
    "    circuit.append(cirq.H(readout))\n",
    "\n",
    "    return circuit, cirq.Z(readout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3649 samples, validate on 890 samples\n",
      "Epoch 1/10\n",
      "3649/3649 [==============================] - 935s 256ms/sample - loss: 0.5820 - hinge_accuracy: 0.8370 - val_loss: 0.2371 - val_hinge_accuracy: 0.9736\n",
      "Epoch 2/10\n",
      "3649/3649 [==============================] - 934s 256ms/sample - loss: 0.1413 - hinge_accuracy: 0.9829 - val_loss: 0.1375 - val_hinge_accuracy: 0.9677\n",
      "Epoch 3/10\n",
      "3649/3649 [==============================] - 933s 256ms/sample - loss: 0.0860 - hinge_accuracy: 0.9878 - val_loss: 0.1385 - val_hinge_accuracy: 0.9696\n",
      "Epoch 4/10\n",
      "3649/3649 [==============================] - 934s 256ms/sample - loss: 0.0690 - hinge_accuracy: 0.9821 - val_loss: 0.1571 - val_hinge_accuracy: 0.9640\n",
      "Epoch 5/10\n",
      "3649/3649 [==============================] - 934s 256ms/sample - loss: 0.0623 - hinge_accuracy: 0.9777 - val_loss: 0.1601 - val_hinge_accuracy: 0.9640\n",
      "Epoch 6/10\n",
      "3649/3649 [==============================] - 935s 256ms/sample - loss: 0.0543 - hinge_accuracy: 0.9777 - val_loss: 0.1914 - val_hinge_accuracy: 0.9651\n",
      "Epoch 7/10\n",
      "3649/3649 [==============================] - 934s 256ms/sample - loss: 0.0415 - hinge_accuracy: 0.9954 - val_loss: 0.2573 - val_hinge_accuracy: 0.9955\n",
      "Epoch 8/10\n",
      "3649/3649 [==============================] - 935s 256ms/sample - loss: 0.0372 - hinge_accuracy: 0.9984 - val_loss: 0.2911 - val_hinge_accuracy: 0.9967\n",
      "Epoch 9/10\n",
      "3649/3649 [==============================] - 934s 256ms/sample - loss: 0.0354 - hinge_accuracy: 0.9984 - val_loss: 0.2804 - val_hinge_accuracy: 0.9967\n",
      "Epoch 10/10\n",
      "3649/3649 [==============================] - 934s 256ms/sample - loss: 0.0344 - hinge_accuracy: 0.9984 - val_loss: 0.3079 - val_hinge_accuracy: 0.9877\n",
      "The training time is 9341.321693658829\n",
      "890/890 [==============================] - 5s 5ms/sample - loss: 0.3079 - hinge_accuracy: 0.9877\n"
     ]
    }
   ],
   "source": [
    "## Shuffle Deep QNN\n",
    "x_train_tfcirc, y_train_hinge = get_mnist_train(16, a=3, b=6)\n",
    "x_test_tfcirc, y_test_hinge = get_mnist_test(16, a=3, b=6, invert=False)\n",
    "\n",
    "try:\n",
    "    del model_circuit, model_readout, model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model_circuit, model_readout = create_shuffle_deep_quantum_model(num_qubits=16)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
    "        tfq.layers.PQC(model_circuit, model_readout),\n",
    "        ], name='shuffle_deep_qnn')\n",
    "\n",
    "model.compile(\n",
    "        loss=tf.keras.losses.Hinge(),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.002),\n",
    "        metrics=[hinge_accuracy])\n",
    "\n",
    "start = time.time()\n",
    "qnn_history = model.fit(\n",
    "        x_train_tfcirc, y_train_hinge,\n",
    "        batch_size=32,\n",
    "        epochs=10,\n",
    "        verbose=1,\n",
    "#         callbacks=callbacks,\n",
    "        validation_data=(x_test_tfcirc, y_test_hinge))\n",
    "end = time.time()\n",
    "print('The training time is {}'.format(end - start))\n",
    "\n",
    "shuffle_qnn_results = model.evaluate(x_test_tfcirc, y_test_hinge) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3649 samples, validate on 890 samples\n",
      "Epoch 1/10\n",
      "3649/3649 [==============================] - 935s 256ms/sample - loss: 0.8230 - hinge_accuracy: 0.7791 - val_loss: 0.6443 - val_hinge_accuracy: 0.7265\n",
      "Epoch 2/10\n",
      "3649/3649 [==============================] - 934s 256ms/sample - loss: 0.2191 - hinge_accuracy: 0.9484 - val_loss: 0.2111 - val_hinge_accuracy: 0.9727\n",
      "Epoch 3/10\n",
      "3649/3649 [==============================] - 933s 256ms/sample - loss: 0.0677 - hinge_accuracy: 0.9812 - val_loss: 0.3321 - val_hinge_accuracy: 0.9794\n",
      "Epoch 4/10\n",
      "3649/3649 [==============================] - 934s 256ms/sample - loss: 0.0499 - hinge_accuracy: 0.9880 - val_loss: 0.3884 - val_hinge_accuracy: 0.7242\n",
      "Epoch 5/10\n",
      "3649/3649 [==============================] - 934s 256ms/sample - loss: 0.0398 - hinge_accuracy: 0.9954 - val_loss: 0.3818 - val_hinge_accuracy: 0.7281\n",
      "Epoch 6/10\n",
      "3328/3649 [==========================>...] - ETA: 1:21 - loss: 0.0360 - hinge_accuracy: 0.9961"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-94d508ef85b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         validation_data=(x_test_tfcirc, y_test_hinge))\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The training time is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Shuffle QNN Domain Adaptation\n",
    "x_train_tfcirc, y_train_hinge = get_mnist_train(16, a=3, b=6)\n",
    "x_test_tfcirc, y_test_hinge = get_mnist_test(16, a=3, b=6)\n",
    "\n",
    "try:\n",
    "    del model_circuit, model_readout, model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model_circuit, model_readout = create_shuffle_deep_quantum_model(num_qubits=16)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
    "        tfq.layers.PQC(model_circuit, model_readout),\n",
    "        ], name='shuffle_deep_qnn_da')\n",
    "\n",
    "model.compile(\n",
    "        loss=tf.keras.losses.Hinge(),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.002),\n",
    "        metrics=[hinge_accuracy])\n",
    "\n",
    "start = time.time()\n",
    "qnn_history = model.fit(\n",
    "        x_train_tfcirc, y_train_hinge,\n",
    "        batch_size=32,\n",
    "        epochs=10,\n",
    "        verbose=1,\n",
    "#         callbacks=callbacks,\n",
    "        validation_data=(x_test_tfcirc, y_test_hinge))\n",
    "end = time.time()\n",
    "print('The training time is {}'.format(end - start))\n",
    "\n",
    "shuffle_qnn_results = model.evaluate(x_test_tfcirc, y_test_hinge) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 37\n",
      "Trainable params: 37\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3649 samples, validate on 890 samples\n",
      "Epoch 1/10\n",
      "3649/3649 - 1s - loss: 0.6307 - accuracy: 0.4333 - val_loss: 0.6490 - val_accuracy: 0.6303\n",
      "Epoch 2/10\n",
      "3649/3649 - 0s - loss: 0.6025 - accuracy: 0.4453 - val_loss: 0.6302 - val_accuracy: 0.6393\n",
      "Epoch 3/10\n",
      "3649/3649 - 0s - loss: 0.5702 - accuracy: 0.4747 - val_loss: 0.6119 - val_accuracy: 0.6618\n",
      "Epoch 4/10\n",
      "3649/3649 - 0s - loss: 0.5329 - accuracy: 0.5152 - val_loss: 0.5849 - val_accuracy: 0.7573\n",
      "Epoch 5/10\n",
      "3649/3649 - 0s - loss: 0.4835 - accuracy: 0.6668 - val_loss: 0.5637 - val_accuracy: 0.8775\n",
      "Epoch 6/10\n",
      "3649/3649 - 0s - loss: 0.4361 - accuracy: 0.8227 - val_loss: 0.5411 - val_accuracy: 0.8921\n",
      "Epoch 7/10\n",
      "3649/3649 - 0s - loss: 0.3881 - accuracy: 0.8411 - val_loss: 0.5122 - val_accuracy: 0.8955\n",
      "Epoch 8/10\n",
      "3649/3649 - 0s - loss: 0.3429 - accuracy: 0.9087 - val_loss: 0.4781 - val_accuracy: 0.9427\n",
      "Epoch 9/10\n",
      "3649/3649 - 0s - loss: 0.3033 - accuracy: 0.9392 - val_loss: 0.4471 - val_accuracy: 0.9719\n",
      "Epoch 10/10\n",
      "3649/3649 - 0s - loss: 0.2686 - accuracy: 0.9696 - val_loss: 0.4188 - val_accuracy: 0.9742\n",
      "The training time is 2.3694591522216797\n",
      "890/890 [==============================] - 0s 52us/sample - loss: 0.4188 - accuracy: 0.9742\n"
     ]
    }
   ],
   "source": [
    "# DNN\n",
    "x_train_bin, y_train = get_mnist_train(16, a=3, b=6, quantum=False)\n",
    "x_test_bin, y_test = get_mnist_test(16, a=3, b=6, quantum=False, invert=False)\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model = create_fair_classical_model(num_qubits=16)\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "start = time.time()\n",
    "model.fit(x_train_bin,\n",
    "          y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=2,\n",
    "#           callbacks=callbacks,\n",
    "          validation_data=(x_test_bin, y_test))\n",
    "end = time.time()\n",
    "print('The training time is {}'.format(end - start))\n",
    "\n",
    "fair_nn_results = model.evaluate(x_test_bin, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_16 (Flatten)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 37\n",
      "Trainable params: 37\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3649 samples, validate on 890 samples\n",
      "Epoch 1/10\n",
      "3649/3649 - 0s - loss: 0.6233 - accuracy: 0.5053 - val_loss: 0.8349 - val_accuracy: 0.3596\n",
      "Epoch 2/10\n",
      "3649/3649 - 0s - loss: 0.6066 - accuracy: 0.6161 - val_loss: 0.8646 - val_accuracy: 0.4247\n",
      "Epoch 3/10\n",
      "3649/3649 - 0s - loss: 0.5911 - accuracy: 0.7991 - val_loss: 0.8961 - val_accuracy: 0.4146\n",
      "Epoch 4/10\n",
      "3649/3649 - 0s - loss: 0.5755 - accuracy: 0.8021 - val_loss: 0.9306 - val_accuracy: 0.1281\n",
      "Epoch 5/10\n",
      "3649/3649 - 0s - loss: 0.5595 - accuracy: 0.7978 - val_loss: 0.9637 - val_accuracy: 0.1371\n",
      "Epoch 6/10\n",
      "3649/3649 - 0s - loss: 0.5429 - accuracy: 0.8145 - val_loss: 0.9994 - val_accuracy: 0.1404\n",
      "Epoch 7/10\n",
      "3649/3649 - 0s - loss: 0.5260 - accuracy: 0.8290 - val_loss: 1.0384 - val_accuracy: 0.1326\n",
      "Epoch 8/10\n",
      "3649/3649 - 0s - loss: 0.5085 - accuracy: 0.8761 - val_loss: 1.0800 - val_accuracy: 0.1270\n",
      "Epoch 9/10\n",
      "3649/3649 - 0s - loss: 0.4906 - accuracy: 0.8844 - val_loss: 1.1267 - val_accuracy: 0.1258\n",
      "Epoch 10/10\n",
      "3649/3649 - 0s - loss: 0.4724 - accuracy: 0.9331 - val_loss: 1.1752 - val_accuracy: 0.1146\n",
      "890/890 [==============================] - 0s 50us/sample - loss: 1.1752 - accuracy: 0.1146\n"
     ]
    }
   ],
   "source": [
    "# DNN Domain Adaptation\n",
    "x_train_bin, y_train = get_mnist_train(16, a=3, b=6, quantum=False)\n",
    "x_test_bin, y_test = get_mnist_test(16, a=3, b=6, quantum=False)\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model = create_fair_classical_model(num_qubits=16)\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train_bin,\n",
    "          y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=2,\n",
    "#           callbacks=callbacks,\n",
    "          validation_data=(x_test_bin, y_test))\n",
    "\n",
    "fair_nn_results = model.evaluate(x_test_bin, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wide_classical_model(num_qubits=16, model_name='wide_dnn'):\n",
    "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
    "    h = get_edge(num_qubits)\n",
    "    model = tf.keras.Sequential(name=model_name)\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(h,h,1)))\n",
    "    model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"wide_dnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 289\n",
      "Trainable params: 289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3649 samples, validate on 890 samples\n",
      "Epoch 1/10\n",
      "3649/3649 - 1s - loss: 0.7183 - accuracy: 0.4316 - val_loss: 0.6586 - val_accuracy: 0.6270\n",
      "Epoch 2/10\n",
      "3649/3649 - 0s - loss: 0.6547 - accuracy: 0.4316 - val_loss: 0.6220 - val_accuracy: 0.6270\n",
      "Epoch 3/10\n",
      "3649/3649 - 0s - loss: 0.5914 - accuracy: 0.4319 - val_loss: 0.5739 - val_accuracy: 0.6281\n",
      "Epoch 4/10\n",
      "3649/3649 - 0s - loss: 0.5160 - accuracy: 0.6522 - val_loss: 0.5136 - val_accuracy: 0.8573\n",
      "Epoch 5/10\n",
      "3649/3649 - 0s - loss: 0.4312 - accuracy: 0.9150 - val_loss: 0.4528 - val_accuracy: 0.9427\n",
      "Epoch 6/10\n",
      "3649/3649 - 0s - loss: 0.3448 - accuracy: 0.9674 - val_loss: 0.3902 - val_accuracy: 0.9764\n",
      "Epoch 7/10\n",
      "3649/3649 - 0s - loss: 0.2675 - accuracy: 0.9940 - val_loss: 0.3297 - val_accuracy: 0.9921\n",
      "Epoch 8/10\n",
      "3649/3649 - 0s - loss: 0.2085 - accuracy: 0.9959 - val_loss: 0.2783 - val_accuracy: 0.9933\n",
      "Epoch 9/10\n",
      "3649/3649 - 0s - loss: 0.1635 - accuracy: 0.9973 - val_loss: 0.2364 - val_accuracy: 0.9933\n",
      "Epoch 10/10\n",
      "3649/3649 - 0s - loss: 0.1301 - accuracy: 0.9981 - val_loss: 0.2033 - val_accuracy: 0.9944\n",
      "890/890 [==============================] - 0s 50us/sample - loss: 0.2033 - accuracy: 0.9944\n"
     ]
    }
   ],
   "source": [
    "# Wide DNN\n",
    "x_train_bin, y_train = get_mnist_train(16, a=3, b=6, quantum=False)\n",
    "x_test_bin, y_test = get_mnist_test(16, a=3, b=6, quantum=False, invert=False)\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model = create_wide_classical_model(num_qubits=16)\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train_bin,\n",
    "          y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=2,\n",
    "#           callbacks=callbacks,\n",
    "          validation_data=(x_test_bin, y_test))\n",
    "\n",
    "wide_nn_results = model.evaluate(x_test_bin, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"wide_dnn_da\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 289\n",
      "Trainable params: 289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3649 samples, validate on 890 samples\n",
      "Epoch 1/10\n",
      "3649/3649 - 0s - loss: 0.5621 - accuracy: 0.4683 - val_loss: 0.7772 - val_accuracy: 0.6270\n",
      "Epoch 2/10\n",
      "3649/3649 - 0s - loss: 0.4628 - accuracy: 0.8378 - val_loss: 0.8490 - val_accuracy: 0.6270\n",
      "Epoch 3/10\n",
      "3649/3649 - 0s - loss: 0.3731 - accuracy: 0.9022 - val_loss: 0.9444 - val_accuracy: 0.6270\n",
      "Epoch 4/10\n",
      "3649/3649 - 0s - loss: 0.2946 - accuracy: 0.9490 - val_loss: 1.0618 - val_accuracy: 0.5663\n",
      "Epoch 5/10\n",
      "3649/3649 - 0s - loss: 0.2285 - accuracy: 0.9594 - val_loss: 1.2073 - val_accuracy: 0.5022\n",
      "Epoch 6/10\n",
      "3649/3649 - 0s - loss: 0.1756 - accuracy: 0.9855 - val_loss: 1.3832 - val_accuracy: 0.4360\n",
      "Epoch 7/10\n",
      "3649/3649 - 0s - loss: 0.1362 - accuracy: 0.9912 - val_loss: 1.5689 - val_accuracy: 0.1910\n",
      "Epoch 8/10\n",
      "3649/3649 - 0s - loss: 0.1072 - accuracy: 0.9923 - val_loss: 1.7542 - val_accuracy: 0.1820\n",
      "Epoch 9/10\n",
      "3649/3649 - 0s - loss: 0.0858 - accuracy: 0.9942 - val_loss: 1.9390 - val_accuracy: 0.1539\n",
      "Epoch 10/10\n",
      "3649/3649 - 0s - loss: 0.0699 - accuracy: 0.9970 - val_loss: 2.1122 - val_accuracy: 0.1528\n",
      "890/890 [==============================] - 0s 50us/sample - loss: 2.1122 - accuracy: 0.1528\n"
     ]
    }
   ],
   "source": [
    "# Wide DNN Domain Adaptation\n",
    "x_train_bin, y_train = get_mnist_train(16, a=3, b=6, quantum=False)\n",
    "x_test_bin, y_test = get_mnist_test(16, a=3, b=6, quantum=False)\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model = create_wide_classical_model(num_qubits=16, model_name='wide_dnn_da')\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train_bin,\n",
    "          y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=2,\n",
    "#           callbacks=callbacks,\n",
    "          validation_data=(x_test_bin, y_test))\n",
    "\n",
    "wide_nn_results = model.evaluate(x_test_bin, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deep_classical_model(num_qubits=16, model_name='deep_dnn'):\n",
    "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
    "    h = get_edge(num_qubits)\n",
    "    model = tf.keras.Sequential(name=model_name)\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(h,h,1)))\n",
    "    model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(2, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deep_dnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 309\n",
      "Trainable params: 309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3649 samples, validate on 890 samples\n",
      "Epoch 1/10\n",
      "3649/3649 - 1s - loss: 0.7143 - accuracy: 0.4311 - val_loss: 0.6957 - val_accuracy: 0.6270\n",
      "Epoch 2/10\n",
      "3649/3649 - 0s - loss: 0.6707 - accuracy: 0.4368 - val_loss: 0.6713 - val_accuracy: 0.6382\n",
      "Epoch 3/10\n",
      "3649/3649 - 0s - loss: 0.6138 - accuracy: 0.5684 - val_loss: 0.6363 - val_accuracy: 0.8472\n",
      "Epoch 4/10\n",
      "3649/3649 - 0s - loss: 0.5533 - accuracy: 0.8345 - val_loss: 0.6090 - val_accuracy: 0.9213\n",
      "Epoch 5/10\n",
      "3649/3649 - 0s - loss: 0.4946 - accuracy: 0.9537 - val_loss: 0.5788 - val_accuracy: 0.9528\n",
      "Epoch 6/10\n",
      "3649/3649 - 0s - loss: 0.4328 - accuracy: 0.9704 - val_loss: 0.5347 - val_accuracy: 0.9618\n",
      "Epoch 7/10\n",
      "3649/3649 - 0s - loss: 0.3644 - accuracy: 0.9827 - val_loss: 0.4741 - val_accuracy: 0.9921\n",
      "Epoch 8/10\n",
      "3649/3649 - 0s - loss: 0.2943 - accuracy: 0.9868 - val_loss: 0.3964 - val_accuracy: 0.9966\n",
      "Epoch 9/10\n",
      "3649/3649 - 0s - loss: 0.2257 - accuracy: 0.9945 - val_loss: 0.3119 - val_accuracy: 0.9978\n",
      "Epoch 10/10\n",
      "3649/3649 - 0s - loss: 0.1636 - accuracy: 0.9989 - val_loss: 0.2334 - val_accuracy: 0.9978\n",
      "890/890 [==============================] - 0s 51us/sample - loss: 0.2334 - accuracy: 0.9978\n"
     ]
    }
   ],
   "source": [
    "# Deep DNN\n",
    "x_train_bin, y_train = get_mnist_train(16, a=3, b=6, quantum=False)\n",
    "x_test_bin, y_test = get_mnist_test(16, a=3, b=6, quantum=False, invert=False)\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model = create_deep_classical_model(num_qubits=16)\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train_bin,\n",
    "          y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=2,\n",
    "#           callbacks=callbacks,\n",
    "          validation_data=(x_test_bin, y_test))\n",
    "\n",
    "deep_nn_results = model.evaluate(x_test_bin, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deep_dnn_da\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 309\n",
      "Trainable params: 309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3649 samples, validate on 890 samples\n",
      "Epoch 1/10\n",
      "3649/3649 - 1s - loss: 0.5600 - accuracy: 0.5369 - val_loss: 0.7529 - val_accuracy: 0.6270\n",
      "Epoch 2/10\n",
      "3649/3649 - 0s - loss: 0.4715 - accuracy: 0.7257 - val_loss: 0.8374 - val_accuracy: 0.6112\n",
      "Epoch 3/10\n",
      "3649/3649 - 0s - loss: 0.3840 - accuracy: 0.9098 - val_loss: 0.9529 - val_accuracy: 0.4112\n",
      "Epoch 4/10\n",
      "3649/3649 - 0s - loss: 0.3003 - accuracy: 0.9586 - val_loss: 1.0975 - val_accuracy: 0.2191\n",
      "Epoch 5/10\n",
      "3649/3649 - 0s - loss: 0.2273 - accuracy: 0.9682 - val_loss: 1.2617 - val_accuracy: 0.0371\n",
      "Epoch 6/10\n",
      "3649/3649 - 0s - loss: 0.1698 - accuracy: 0.9948 - val_loss: 1.4645 - val_accuracy: 0.0213\n",
      "Epoch 7/10\n",
      "3649/3649 - 0s - loss: 0.1261 - accuracy: 0.9978 - val_loss: 1.6865 - val_accuracy: 0.0157\n",
      "Epoch 8/10\n",
      "3649/3649 - 0s - loss: 0.0938 - accuracy: 0.9992 - val_loss: 1.9459 - val_accuracy: 0.0146\n",
      "Epoch 9/10\n",
      "3649/3649 - 0s - loss: 0.0699 - accuracy: 0.9997 - val_loss: 2.2231 - val_accuracy: 0.0157\n",
      "Epoch 10/10\n",
      "3649/3649 - 0s - loss: 0.0525 - accuracy: 0.9997 - val_loss: 2.4904 - val_accuracy: 0.0067\n",
      "890/890 [==============================] - 0s 51us/sample - loss: 2.4904 - accuracy: 0.0067\n"
     ]
    }
   ],
   "source": [
    "# Deep DNN Domain Adaptation\n",
    "x_train_bin, y_train = get_mnist_train(16, a=3, b=6, quantum=False)\n",
    "x_test_bin, y_test = get_mnist_test(16, a=3, b=6, quantum=False)\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model = create_deep_classical_model(num_qubits=16, model_name='deep_dnn_da')\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train_bin,\n",
    "          y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=2,\n",
    "#           callbacks=callbacks,\n",
    "          validation_data=(x_test_bin, y_test))\n",
    "\n",
    "deep_nn_results = model.evaluate(x_test_bin, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_large_classical_model(num_qubits=16, model_name='large_dnn'):\n",
    "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
    "    h = get_edge(num_qubits)\n",
    "    model = tf.keras.Sequential(name=model_name)\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(h,h,1)))\n",
    "    model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"large_dnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 561\n",
      "Trainable params: 561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3649 samples, validate on 890 samples\n",
      "Epoch 1/10\n",
      "3649/3649 - 1s - loss: 0.6577 - accuracy: 0.4560 - val_loss: 0.6911 - val_accuracy: 0.7719\n",
      "Epoch 2/10\n",
      "3649/3649 - 0s - loss: 0.5671 - accuracy: 0.8517 - val_loss: 0.6136 - val_accuracy: 0.9764\n",
      "Epoch 3/10\n",
      "3649/3649 - 0s - loss: 0.4441 - accuracy: 0.9729 - val_loss: 0.5102 - val_accuracy: 0.9921\n",
      "Epoch 4/10\n",
      "3649/3649 - 0s - loss: 0.3289 - accuracy: 0.9792 - val_loss: 0.4016 - val_accuracy: 0.9921\n",
      "Epoch 5/10\n",
      "3649/3649 - 0s - loss: 0.2341 - accuracy: 0.9874 - val_loss: 0.2796 - val_accuracy: 0.9933\n",
      "Epoch 6/10\n",
      "3649/3649 - 0s - loss: 0.1515 - accuracy: 0.9975 - val_loss: 0.1757 - val_accuracy: 0.9933\n",
      "Epoch 7/10\n",
      "3649/3649 - 0s - loss: 0.0892 - accuracy: 0.9981 - val_loss: 0.1103 - val_accuracy: 0.9933\n",
      "Epoch 8/10\n",
      "3649/3649 - 0s - loss: 0.0523 - accuracy: 0.9981 - val_loss: 0.0763 - val_accuracy: 0.9708\n",
      "Epoch 9/10\n",
      "3649/3649 - 0s - loss: 0.0326 - accuracy: 0.9986 - val_loss: 0.0595 - val_accuracy: 0.9753\n",
      "Epoch 10/10\n",
      "3649/3649 - 0s - loss: 0.0221 - accuracy: 0.9997 - val_loss: 0.0500 - val_accuracy: 0.9753\n",
      "890/890 [==============================] - 0s 52us/sample - loss: 0.0500 - accuracy: 0.9753\n"
     ]
    }
   ],
   "source": [
    "# Large DNN\n",
    "x_train_bin, y_train = get_mnist_train(16, a=3, b=6, quantum=False)\n",
    "x_test_bin, y_test = get_mnist_test(16, a=3, b=6, quantum=False, invert=False)\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model = create_large_classical_model(num_qubits=16)\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train_bin,\n",
    "          y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=2,\n",
    "#           callbacks=callbacks,\n",
    "          validation_data=(x_test_bin, y_test))\n",
    "\n",
    "large_nn_results = model.evaluate(x_test_bin, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"large_dnn_da\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 561\n",
      "Trainable params: 561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3649 samples, validate on 890 samples\n",
      "Epoch 1/10\n",
      "3649/3649 - 1s - loss: 0.6102 - accuracy: 0.5103 - val_loss: 0.9369 - val_accuracy: 0.3079\n",
      "Epoch 2/10\n",
      "3649/3649 - 0s - loss: 0.4815 - accuracy: 0.8339 - val_loss: 1.2931 - val_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "3649/3649 - 0s - loss: 0.3557 - accuracy: 0.9627 - val_loss: 1.7792 - val_accuracy: 0.0281\n",
      "Epoch 4/10\n",
      "3649/3649 - 0s - loss: 0.2338 - accuracy: 0.9800 - val_loss: 2.3977 - val_accuracy: 0.0079\n",
      "Epoch 5/10\n",
      "3649/3649 - 0s - loss: 0.1375 - accuracy: 0.9849 - val_loss: 3.1097 - val_accuracy: 0.0247\n",
      "Epoch 6/10\n",
      "3649/3649 - 0s - loss: 0.0755 - accuracy: 0.9901 - val_loss: 3.8008 - val_accuracy: 0.0247\n",
      "Epoch 7/10\n",
      "3649/3649 - 0s - loss: 0.0439 - accuracy: 0.9942 - val_loss: 4.3484 - val_accuracy: 0.0124\n",
      "Epoch 8/10\n",
      "3649/3649 - 0s - loss: 0.0282 - accuracy: 0.9978 - val_loss: 4.7390 - val_accuracy: 0.0124\n",
      "Epoch 9/10\n",
      "3649/3649 - 0s - loss: 0.0196 - accuracy: 0.9986 - val_loss: 5.0595 - val_accuracy: 0.0112\n",
      "Epoch 10/10\n",
      "3649/3649 - 0s - loss: 0.0143 - accuracy: 0.9992 - val_loss: 5.3609 - val_accuracy: 0.0090\n",
      "890/890 [==============================] - 0s 50us/sample - loss: 5.3609 - accuracy: 0.0090\n"
     ]
    }
   ],
   "source": [
    "# Large DNN Domain Adaptation\n",
    "x_train_bin, y_train = get_mnist_train(16, a=3, b=6, quantum=False)\n",
    "x_test_bin, y_test = get_mnist_test(16, a=3, b=6, quantum=False)\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model = create_large_classical_model(num_qubits=16, model_name='large_dnn_da')\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train_bin,\n",
    "          y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=2,\n",
    "#           callbacks=callbacks,\n",
    "          validation_data=(x_test_bin, y_test))\n",
    "\n",
    "large_nn_results = model.evaluate(x_test_bin, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.001\n",
      "Accuracy:  0.9786516853932584\n",
      "\n",
      "Accuracy:  0.016853932584269662\n",
      "\n",
      "C = 0.01\n",
      "Accuracy:  0.9943820224719101\n",
      "\n",
      "Accuracy:  0.0056179775280898875\n",
      "\n",
      "C = 0.1\n",
      "Accuracy:  0.9752808988764045\n",
      "\n",
      "Accuracy:  0.025842696629213482\n",
      "\n",
      "C = 1\n",
      "Accuracy:  0.9752808988764045\n",
      "\n",
      "Accuracy:  0.3707865168539326\n",
      "\n",
      "C = 10\n",
      "Accuracy:  0.9977528089887641\n",
      "\n",
      "Accuracy:  0.15056179775280898\n",
      "\n",
      "C = 100\n",
      "Accuracy:  0.9977528089887641\n",
      "\n",
      "Accuracy:  0.011235955056179775\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train_bin, y_train = get_mnist_train(16, a=3, b=6, quantum=False)\n",
    "x_test_bin, y_test = get_mnist_test(16, a=3, b=6, quantum=False, invert=False)\n",
    "num_train = len(x_train_bin)\n",
    "x_train_bin = tf.reshape(x_train_bin, [num_train, -1]).numpy()\n",
    "num_test = len(x_test_bin)\n",
    "x_test_bin = tf.reshape(x_test_bin, [num_test, -1]).numpy()\n",
    "\n",
    "x_test_bin_in, y_test_in = get_mnist_test(16, a=3, b=6, quantum=False)\n",
    "num_test = len(x_test_bin_in)\n",
    "x_test_bin_in = tf.reshape(x_test_bin_in, [num_test, -1]).numpy()\n",
    "\n",
    "for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    print('C = {}'.format(C))\n",
    "    clf = svm.SVC(C=C, kernel='linear')\n",
    "    clf.fit(x_train_bin, y_train)\n",
    "    y_pred = clf.predict(x_test_bin)\n",
    "    print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "    print()    \n",
    "    y_pred = clf.predict(x_test_bin_in)\n",
    "    print('Accuracy: ', accuracy_score(y_test_in, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.001\n",
      "Accuracy:  0.5584269662921348\n",
      "\n",
      "Accuracy:  0.37303370786516854\n",
      "\n",
      "C = 0.01\n",
      "Accuracy:  0.9932584269662922\n",
      "\n",
      "Accuracy:  0.37303370786516854\n",
      "\n",
      "C = 0.1\n",
      "Accuracy:  0.9977528089887641\n",
      "\n",
      "Accuracy:  0.0449438202247191\n",
      "\n",
      "C = 1\n",
      "Accuracy:  0.9752808988764045\n",
      "\n",
      "Accuracy:  0.37303370786516854\n",
      "\n",
      "C = 10\n",
      "Accuracy:  0.9752808988764045\n",
      "\n",
      "Accuracy:  0.37303370786516854\n",
      "\n",
      "C = 100\n",
      "Accuracy:  0.9752808988764045\n",
      "\n",
      "Accuracy:  0.37303370786516854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train_bin, y_train = get_mnist_train(16, a=3, b=6, quantum=False)\n",
    "x_test_bin, y_test = get_mnist_test(16, a=3, b=6, quantum=False, invert=False)\n",
    "num_train = len(x_train_bin)\n",
    "x_train_bin = tf.reshape(x_train_bin, [num_train, -1]).numpy()\n",
    "num_test = len(x_test_bin)\n",
    "x_test_bin = tf.reshape(x_test_bin, [num_test, -1]).numpy()\n",
    "\n",
    "x_test_bin_in, y_test_in = get_mnist_test(16, a=3, b=6, quantum=False)\n",
    "num_test = len(x_test_bin_in)\n",
    "x_test_bin_in = tf.reshape(x_test_bin_in, [num_test, -1]).numpy()\n",
    "\n",
    "for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    print('C = {}'.format(C))\n",
    "    clf = svm.SVC(C=C, kernel='rbf')\n",
    "    clf.fit(x_train_bin, y_train)\n",
    "    y_pred = clf.predict(x_test_bin)\n",
    "    print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "    print()    \n",
    "    y_pred = clf.predict(x_test_bin_in)\n",
    "    print('Accuracy: ', accuracy_score(y_test_in, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(num_qubits=16, model_name='cnn'):\n",
    "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
    "    h = get_edge(num_qubits)\n",
    "    model = tf.keras.Sequential(name=model_name)\n",
    "    model.add(tf.keras.layers.Conv2D(16, [3, 3], activation='relu', input_shape=(h,h,1), padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.Conv2D(16, [3, 3], activation='relu', padding='same'))\n",
    "    model.add(tf.keras.layers.AveragePooling2D())\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 4, 4, 16)          160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 2, 2, 16)          2320      \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,497\n",
      "Trainable params: 2,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3649 samples, validate on 890 samples\n",
      "Epoch 1/15\n",
      "3649/3649 - 4s - loss: 0.6503 - accuracy: 0.4316 - val_loss: 0.6672 - val_accuracy: 0.6303\n",
      "Epoch 2/15\n",
      "3649/3649 - 0s - loss: 0.5576 - accuracy: 0.7542 - val_loss: 0.5689 - val_accuracy: 0.9315\n",
      "Epoch 3/15\n",
      "3649/3649 - 0s - loss: 0.4138 - accuracy: 0.9474 - val_loss: 0.4209 - val_accuracy: 0.9483\n",
      "Epoch 4/15\n",
      "3649/3649 - 0s - loss: 0.2576 - accuracy: 0.9666 - val_loss: 0.2848 - val_accuracy: 0.9584\n",
      "Epoch 5/15\n",
      "3649/3649 - 0s - loss: 0.1516 - accuracy: 0.9762 - val_loss: 0.1923 - val_accuracy: 0.9584\n",
      "Epoch 6/15\n",
      "3649/3649 - 0s - loss: 0.0967 - accuracy: 0.9805 - val_loss: 0.1482 - val_accuracy: 0.9607\n",
      "Epoch 7/15\n",
      "3649/3649 - 0s - loss: 0.0672 - accuracy: 0.9866 - val_loss: 0.1283 - val_accuracy: 0.9876\n",
      "Epoch 8/15\n",
      "3649/3649 - 0s - loss: 0.0497 - accuracy: 0.9912 - val_loss: 0.1136 - val_accuracy: 0.9876\n",
      "Epoch 9/15\n",
      "3649/3649 - 0s - loss: 0.0386 - accuracy: 0.9931 - val_loss: 0.0936 - val_accuracy: 0.9899\n",
      "Epoch 10/15\n",
      "3649/3649 - 0s - loss: 0.0305 - accuracy: 0.9948 - val_loss: 0.0943 - val_accuracy: 0.9944\n",
      "Epoch 11/15\n",
      "3649/3649 - 0s - loss: 0.0243 - accuracy: 0.9953 - val_loss: 0.0924 - val_accuracy: 0.9944\n",
      "Epoch 12/15\n",
      "3649/3649 - 0s - loss: 0.0201 - accuracy: 0.9956 - val_loss: 0.0867 - val_accuracy: 0.9955\n",
      "Epoch 13/15\n",
      "3649/3649 - 0s - loss: 0.0165 - accuracy: 0.9970 - val_loss: 0.0654 - val_accuracy: 0.9944\n",
      "Epoch 14/15\n",
      "3649/3649 - 0s - loss: 0.0139 - accuracy: 0.9970 - val_loss: 0.0677 - val_accuracy: 0.9955\n",
      "Epoch 15/15\n",
      "3649/3649 - 0s - loss: 0.0118 - accuracy: 0.9975 - val_loss: 0.0613 - val_accuracy: 0.9955\n",
      "The training time is 5.46347188949585\n",
      "890/890 [==============================] - 0s 91us/sample - loss: 0.0613 - accuracy: 0.9955\n"
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "x_train_bin, y_train = get_mnist_train(16, a=3, b=6, quantum=False)\n",
    "x_test_bin, y_test = get_mnist_test(16, a=3, b=6, quantum=False, invert=False)\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model = create_cnn(num_qubits=16, model_name='cnn')\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "start = time.time()\n",
    "model.fit(x_train_bin,\n",
    "          y_train,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          verbose=2,\n",
    "#           callbacks=callbacks,\n",
    "          validation_data=(x_test_bin, y_test))\n",
    "end = time.time()\n",
    "print('The training time is {}'.format(end - start))\n",
    "\n",
    "cnn_results = model.evaluate(x_test_bin, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_da\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 16)          160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 16)          2320      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,497\n",
      "Trainable params: 2,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3649 samples, validate on 890 samples\n",
      "Epoch 1/15\n",
      "3649/3649 - 1s - loss: 0.6580 - accuracy: 0.4319 - val_loss: 0.7703 - val_accuracy: 0.6270\n",
      "Epoch 2/15\n",
      "3649/3649 - 0s - loss: 0.5604 - accuracy: 0.7564 - val_loss: 0.7933 - val_accuracy: 0.5573\n",
      "Epoch 3/15\n",
      "3649/3649 - 0s - loss: 0.4081 - accuracy: 0.9331 - val_loss: 0.9220 - val_accuracy: 0.2640\n",
      "Epoch 4/15\n",
      "3649/3649 - 0s - loss: 0.2429 - accuracy: 0.9655 - val_loss: 1.1262 - val_accuracy: 0.1966\n",
      "Epoch 5/15\n",
      "3649/3649 - 0s - loss: 0.1359 - accuracy: 0.9701 - val_loss: 1.3713 - val_accuracy: 0.1416\n",
      "Epoch 6/15\n",
      "3649/3649 - 0s - loss: 0.0864 - accuracy: 0.9729 - val_loss: 1.5616 - val_accuracy: 0.1449\n",
      "Epoch 7/15\n",
      "3649/3649 - 0s - loss: 0.0618 - accuracy: 0.9855 - val_loss: 1.7575 - val_accuracy: 0.1360\n",
      "Epoch 8/15\n",
      "3649/3649 - 0s - loss: 0.0470 - accuracy: 0.9879 - val_loss: 1.8650 - val_accuracy: 0.1438\n",
      "Epoch 9/15\n",
      "3649/3649 - 0s - loss: 0.0371 - accuracy: 0.9912 - val_loss: 1.9910 - val_accuracy: 0.1438\n",
      "Epoch 10/15\n",
      "3649/3649 - 0s - loss: 0.0300 - accuracy: 0.9934 - val_loss: 2.0474 - val_accuracy: 0.1438\n",
      "Epoch 11/15\n",
      "3649/3649 - 0s - loss: 0.0246 - accuracy: 0.9956 - val_loss: 2.1595 - val_accuracy: 0.1416\n",
      "Epoch 12/15\n",
      "3649/3649 - 0s - loss: 0.0206 - accuracy: 0.9970 - val_loss: 2.2355 - val_accuracy: 0.1404\n",
      "Epoch 13/15\n",
      "3649/3649 - 0s - loss: 0.0172 - accuracy: 0.9970 - val_loss: 2.2241 - val_accuracy: 0.2888\n",
      "Epoch 14/15\n",
      "3649/3649 - 0s - loss: 0.0146 - accuracy: 0.9973 - val_loss: 2.2514 - val_accuracy: 0.2888\n",
      "Epoch 15/15\n",
      "3649/3649 - 0s - loss: 0.0126 - accuracy: 0.9975 - val_loss: 2.3081 - val_accuracy: 0.2888\n",
      "890/890 [==============================] - 0s 57us/sample - loss: 2.3081 - accuracy: 0.2888\n"
     ]
    }
   ],
   "source": [
    "# CNN DA\n",
    "x_train_bin, y_train = get_mnist_train(16, a=3, b=6, quantum=False)\n",
    "x_test_bin, y_test = get_mnist_test(16, a=3, b=6, quantum=False)\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model = create_cnn(num_qubits=16, model_name='cnn_da')\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train_bin,\n",
    "          y_train,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          verbose=2,\n",
    "#           callbacks=callbacks,\n",
    "          validation_data=(x_test_bin, y_test))\n",
    "\n",
    "cnn_results = model.evaluate(x_test_bin, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deep_cnn(num_qubits=16, model_name='cnn'):\n",
    "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
    "    h = get_edge(num_qubits)\n",
    "    model = tf.keras.Sequential(name=model_name)\n",
    "    model.add(tf.keras.layers.Conv2D(16, [3, 3], activation='relu', input_shape=(h,h,1), padding='same'))\n",
    "    model.add(tf.keras.layers.Conv2D(16, [3, 3], activation='relu', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.Conv2D(16, [3, 3], activation='relu', padding='same'))\n",
    "    model.add(tf.keras.layers.Conv2D(16, [3, 3], activation='relu', padding='same'))\n",
    "    model.add(tf.keras.layers.AveragePooling2D())\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deep_cnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 16)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 16)          2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 16)          2320      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 2, 16)          2320      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 7,137\n",
      "Trainable params: 7,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3649 samples, validate on 890 samples\n",
      "Epoch 1/15\n",
      "3649/3649 - 5s - loss: 0.6571 - accuracy: 0.4316 - val_loss: 0.5957 - val_accuracy: 0.6270\n",
      "Epoch 2/15\n",
      "3649/3649 - 0s - loss: 0.3196 - accuracy: 0.8594 - val_loss: 0.1349 - val_accuracy: 0.9663\n",
      "Epoch 3/15\n",
      "3649/3649 - 0s - loss: 0.0347 - accuracy: 0.9918 - val_loss: 0.0568 - val_accuracy: 0.9888\n",
      "Epoch 4/15\n",
      "3649/3649 - 0s - loss: 0.0111 - accuracy: 0.9973 - val_loss: 0.0480 - val_accuracy: 0.9730\n",
      "Epoch 5/15\n",
      "3649/3649 - 0s - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.0556 - val_accuracy: 0.9742\n",
      "Epoch 6/15\n",
      "3649/3649 - 0s - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0410 - val_accuracy: 0.9753\n",
      "Epoch 7/15\n",
      "3649/3649 - 0s - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0340 - val_accuracy: 0.9753\n",
      "Epoch 8/15\n",
      "3649/3649 - 0s - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0506 - val_accuracy: 0.9753\n",
      "Epoch 9/15\n",
      "3649/3649 - 0s - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0302 - val_accuracy: 0.9753\n",
      "Epoch 10/15\n",
      "3649/3649 - 0s - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0430 - val_accuracy: 0.9753\n",
      "Epoch 11/15\n",
      "3649/3649 - 0s - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0549 - val_accuracy: 0.9753\n",
      "Epoch 12/15\n",
      "3649/3649 - 0s - loss: 9.6482e-04 - accuracy: 0.9997 - val_loss: 0.0419 - val_accuracy: 0.9753\n",
      "Epoch 13/15\n",
      "3649/3649 - 0s - loss: 6.9297e-04 - accuracy: 0.9997 - val_loss: 0.0394 - val_accuracy: 0.9753\n",
      "Epoch 14/15\n",
      "3649/3649 - 0s - loss: 8.5910e-04 - accuracy: 0.9997 - val_loss: 0.0443 - val_accuracy: 0.9753\n",
      "Epoch 15/15\n",
      "3649/3649 - 0s - loss: 5.9385e-04 - accuracy: 0.9997 - val_loss: 0.0230 - val_accuracy: 0.9978\n",
      "890/890 [==============================] - 0s 105us/sample - loss: 0.0230 - accuracy: 0.9978\n"
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "x_train_bin, y_train = get_mnist_train(16, a=3, b=6, quantum=False)\n",
    "x_test_bin, y_test = get_mnist_test(16, a=3, b=6, quantum=False, invert=False)\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model = create_deep_cnn(num_qubits=16, model_name='deep_cnn')\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train_bin,\n",
    "          y_train,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          verbose=2,\n",
    "#           callbacks=callbacks,\n",
    "          validation_data=(x_test_bin, y_test))\n",
    "\n",
    "cnn_results = model.evaluate(x_test_bin, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deep_cnn_da\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 16)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 16)          2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 2, 2, 16)          2320      \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 2, 2, 16)          2320      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 7,137\n",
      "Trainable params: 7,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3649 samples, validate on 890 samples\n",
      "Epoch 1/15\n",
      "3649/3649 - 1s - loss: 0.6432 - accuracy: 0.4508 - val_loss: 0.8126 - val_accuracy: 0.5517\n",
      "Epoch 2/15\n",
      "3649/3649 - 0s - loss: 0.2747 - accuracy: 0.9512 - val_loss: 1.9730 - val_accuracy: 0.0416\n",
      "Epoch 3/15\n",
      "3649/3649 - 0s - loss: 0.0251 - accuracy: 0.9937 - val_loss: 3.1585 - val_accuracy: 0.0337\n",
      "Epoch 4/15\n",
      "3649/3649 - 0s - loss: 0.0065 - accuracy: 0.9986 - val_loss: 4.1590 - val_accuracy: 0.0416\n",
      "Epoch 5/15\n",
      "3649/3649 - 0s - loss: 0.0033 - accuracy: 0.9997 - val_loss: 5.2042 - val_accuracy: 0.2382\n",
      "Epoch 6/15\n",
      "3649/3649 - 0s - loss: 0.0029 - accuracy: 0.9995 - val_loss: 6.1723 - val_accuracy: 0.3618\n",
      "Epoch 7/15\n",
      "3649/3649 - 0s - loss: 0.0030 - accuracy: 0.9997 - val_loss: 4.3677 - val_accuracy: 0.0056\n",
      "Epoch 8/15\n",
      "3649/3649 - 0s - loss: 0.0016 - accuracy: 0.9997 - val_loss: 5.3368 - val_accuracy: 0.0382\n",
      "Epoch 9/15\n",
      "3649/3649 - 0s - loss: 0.0012 - accuracy: 0.9997 - val_loss: 7.2653 - val_accuracy: 0.3618\n",
      "Epoch 10/15\n",
      "3649/3649 - 0s - loss: 7.6336e-04 - accuracy: 1.0000 - val_loss: 5.7919 - val_accuracy: 0.0382\n",
      "Epoch 11/15\n",
      "3649/3649 - 0s - loss: 9.1149e-04 - accuracy: 0.9997 - val_loss: 7.5915 - val_accuracy: 0.3618\n",
      "Epoch 12/15\n",
      "3649/3649 - 0s - loss: 8.2290e-04 - accuracy: 1.0000 - val_loss: 6.5101 - val_accuracy: 0.0775\n",
      "Epoch 13/15\n",
      "3649/3649 - 0s - loss: 6.1924e-04 - accuracy: 0.9997 - val_loss: 5.8995 - val_accuracy: 0.0303\n",
      "Epoch 14/15\n",
      "3649/3649 - 0s - loss: 9.4294e-04 - accuracy: 0.9997 - val_loss: 6.6716 - val_accuracy: 0.0708\n",
      "Epoch 15/15\n",
      "3649/3649 - 0s - loss: 4.6385e-04 - accuracy: 0.9997 - val_loss: 8.4704 - val_accuracy: 0.3618\n",
      "890/890 [==============================] - 0s 64us/sample - loss: 8.4704 - accuracy: 0.3618\n"
     ]
    }
   ],
   "source": [
    "# Deep CNN DA\n",
    "x_train_bin, y_train = get_mnist_train(16, a=3, b=6, quantum=False)\n",
    "x_test_bin, y_test = get_mnist_test(16, a=3, b=6, quantum=False)\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model = create_deep_cnn(num_qubits=16, model_name='deep_cnn_da')\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train_bin,\n",
    "          y_train,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          verbose=2,\n",
    "#           callbacks=callbacks,\n",
    "          validation_data=(x_test_bin, y_test))\n",
    "\n",
    "cnn_results = model.evaluate(x_test_bin, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
